{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Using matplotlib backend: <object object at 0x0000029D04DC76A0>\n","%pylab is deprecated, use %matplotlib inline and import the required libraries.\n","Populating the interactive namespace from numpy and matplotlib\n"]}],"source":["%pylab\n","%matplotlib inline\n","import numpy\n","import skimage.io"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# K Nearest neighbors \n","https://realpython.com/knn-python/\n","\n","## Was ist das? \n","- Nicht-linearer Algorithmus\n","- **Klassifikation** und **Regression**\n","\n","## Erste Schritte\n","\n","### Preparations\n","- Import der Daten \n","- 'Reshaping' (da CSV, rasterize?)\n","- NumPy array erstellen\n","\n","```\n",">>> abalone.columns = [\n","...     \"Col1\",\n","...     \"Col2\",\n","...     \"Col3\",\n","...     \"Col4\",\n","...     \"Col5\",\n","...     \"Col6\",\n","...     \"Col7\",\n","...     \"Col8\",\n","...     \"Col9\",\n","... ]\n","```\n","\n","*change column names as needed*\n","\n","```\n",">>> clothes = clothes.drop(\"Col1\", axis=1)\n","```\n","Löscht Col1 \n","\n","- **Import von matplotlib.pyplot**\n","\n","### Welche Korrelationen liegen vor?\n","```\n",">>> correlation_matrix = abalone.corr()\n",">>> correlation_matrix[\"Rings\"]\n","```\n","\n","## Mathematische Grundlagen\n","- Berechnen der Distanz zweier Punkte -> *Euklidische Distanz* (Andere Distanzen S. VL)\n","\n","-> Geht alles auch via scikit-learn (machine learning Paket in Python) -> Frage: Dürfen wir das verwenden? \n","\n","```\n",">>> from sklearn.model_selection import train_test_split\n",">>> X_train, X_test, y_train, y_test = train_test_split(\n","...     X, y, test_size=0.2, random_state=12345\n","... )\n","\n",">>> knn_model.fit(X_train, y_train)\n","\n",">>> from sklearn.metrics import mean_squared_error\n",">>> from math import sqrt\n",">>> train_preds = knn_model.predict(X_train)\n",">>> mse = mean_squared_error(y_train, train_preds)\n",">>> rmse = sqrt(mse)\n",">>> rmse\n","\n",">>> test_preds = knn_model.predict(X_test)\n",">>> mse = mean_squared_error(y_test, test_preds)\n",">>> rmse = sqrt(mse)\n",">>> rmse\n","\n",">>> import seaborn as sns\n",">>> cmap = sns.cubehelix_palette(as_cmap=True)\n",">>> f, ax = plt.subplots()\n",">>> points = ax.scatter(\n","...     X_test[:, 0], X_test[:, 1], c=test_preds, s=50, cmap=cmap\n","... )\n",">>> f.colorbar(points)\n",">>> plt.show()\n","\n",">>> cmap = sns.cubehelix_palette(as_cmap=True)\n",">>> f, ax = plt.subplots()\n",">>> points = ax.scatter(\n","...     X_test[:, 0], X_test[:, 1], c=y_test, s=50, cmap=cmap\n",">>> )\n",">>> f.colorbar(points)\n",">>> plt.show()\n","\n",">>> from sklearn.model_selection import GridSearchCV\n",">>> parameters = {\"n_neighbors\": range(1, 50)}\n",">>> gridsearch = GridSearchCV(KNeighborsRegressor(), parameters)\n",">>> gridsearch.fit(X_train, y_train)\n","GridSearchCV(estimator=KNeighborsRegressor(),\n","             param_grid={'n_neighbors': range(1, 50),\n","                         'weights': ['uniform', 'distance']})\n",">>> gridsearch.best_params_\n","{'n_neighbors': 25, 'weights': 'distance'}\n","\n",">>> train_preds_grid = gridsearch.predict(X_train)\n",">>> train_mse = mean_squared_error(y_train, train_preds_grid)\n",">>> train_rmse = sqrt(train_mse)\n",">>> test_preds_grid = gridsearch.predict(X_test)\n",">>> test_mse = mean_squared_error(y_test, test_preds_grid)\n",">>> test_rmse = sqrt(test_mse)\n",">>> train_rmse\n",">>> test_rmse\n","\n",">>> parameters = {\n","...     \"n_neighbors\": range(1, 50),\n","...     \"weights\": [\"uniform\", \"distance\"],\n","... }\n",">>> gridsearch = GridSearchCV(KNeighborsRegressor(), parameters)\n",">>> gridsearch.fit(X_train, y_train)\n","GridSearchCV(estimator=KNeighborsRegressor(),\n","             param_grid={'n_neighbors': range(1, 50),\n","                         'weights': ['uniform', 'distance']})\n",">>> gridsearch.best_params_\n","{'n_neighbors': 25, 'weights': 'distance'}\n",">>> test_preds_grid = gridsearch.predict(X_test)\n",">>> test_mse = mean_squared_error(y_test, test_preds_grid)\n",">>> test_rmse = sqrt(test_mse)\n",">>> test_rmse\n","\n","\n",">>> best_k = gridsearch.best_params_[\"n_neighbors\"]\n",">>> best_weights = gridsearch.best_params_[\"weights\"]\n",">>> bagged_knn = KNeighborsRegressor(\n","...     n_neighbors=best_k, weights=best_weights\n","... )\n","\n",">>> from sklearn.ensemble import BaggingRegressor\n",">>> bagging_model = BaggingRegressor(bagged_knn, n_estimators=100)\n","\n",">>> test_preds_grid = bagging_model.predict(X_test)\n",">>> test_mse = mean_squared_error(y_test, test_preds_grid)\n",">>> test_rmse = sqrt(test_mse)\n",">>> test_rmse\n","```\n","*was dieser Code macht keine Ahnung but I found it... lohnt sich evtl. mal zu fragen, ob wir das Paket verwenden dürfen und sich dann mal reinzulesen*"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
