{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current status\n",
    "<span style=\"color:red\">\n",
    "- Abstract <br>\n",
    "- Introduction <br>\n",
    "</span>\n",
    "<span style=\"color:green\">\n",
    "- Dataset <br>\n",
    "</span>\n",
    "<span style=\"color:green\">\n",
    "- Imports <br>\n",
    "</span>\n",
    "<span style=\"color:green\">\n",
    "-  Z-transformation <br>\n",
    "- PCA <br>\n",
    "</span>\n",
    "<span style=\"color:yellow\">\n",
    "- KNN <br>\n",
    "</span>\n",
    "<span style=\"color:yellow\">\n",
    "- KD-Trees <br>\n",
    "</span>\n",
    "<span style=\"color:yellow\">\n",
    "- CNN (Softmax & Training ist noch nicht drin)<br>\n",
    "</span>\n",
    "<span style=\"color:yellow\">\n",
    "- Evaluation Methods (Wie erklärt man unsere Confusion Matrix mit chi-squared??)<br>\n",
    "</span>\n",
    "<span style=\"color:red\">\n",
    "- Results <br>\n",
    "- Discussion <br>\n",
    "</span>\n",
    "- "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "\n",
    "- In this work we investigate and compare the image classification algorithms KNN and CNN\n",
    "- We reduce dimensions using Principal Component Analysis (PCA) and apply these algorithms to Zalandos Fashion MNIST dataset. \n",
    "- Improved efficiency implementing KD-Trees \n",
    "- Comparison of the two algorithms using different metrics\n",
    "- CNN yielded significatly better accuracy compared to KNN\n",
    "- Findings: especially shirts and t-shirts often confused, significantly better results when the two classes were summarized for KNN and CNN \n",
    "<span style=\"color:red\">\n",
    "- What's KNN, what's CNN <br>\n",
    "- Whats the goal of our project? <br>\n",
    "- What is our extra work (zB KD Trees, special CNN for shirts and T-Shirts) <br>\n",
    "- Main result: KNN worked suprisingly good compared to CNN <br>\n",
    "</span>\n",
    "\n",
    "# Introduction\n",
    "\n",
    "- Object classification and recognition extensive field in computer vision with many applications ranging from facial recognition to autonomous driving\n",
    "- Different algorithms optimal for different Datasets: Traditional machine learning algorithms such as SVMs, KNNs, regression Algorithms\n",
    "- Neural networks for image recognition: CNNs\n",
    "*letzte beiden Punkte bitte gut recherchieren und zitieren thx*\n",
    "\n",
    "- We chose KNN and CNN for classification\n",
    "- Object we analyze is Zalandos Fashion MNIST Dataset (citation needed), a balanced dataset comprised of 60000 training images and 10000 test images \n",
    "- Evtl. bereits bestehende CNN und KNN Algorithmen zitieren?\n",
    "\n",
    "Project is divided into three parts: Data preparation, KNN, CNN\n",
    "\n",
    "Data preparation: Loading and reshaping data, performing dimension reduction via PCA\n",
    "\n",
    "Short KNN introduction: KNN is algorithm, that assigns each training image to a point in a multidimensional space\n",
    "- test image is positioned -> class assigned, that the majority of k-nearest neighbors belong to\n",
    "(evtl. bessere Formulierung? citation needed)\n",
    "\n",
    "CNN:\n",
    "- explanation (evtl mittels Hannahs PDF)\n",
    "Modification of established vgg-architecture (citation needed)\n",
    "\n",
    "# Material\n",
    "\n",
    "### Dataset\n",
    "- MNIST fashion data set\n",
    "\n",
    "### Imports\n",
    "- auf .yml File verweisen\n",
    "\n",
    "# Methods \n",
    "- Z-transformation\n",
    "    - Centering and scaling the data \n",
    "    - Formel? ist das nötig? \n",
    "- PCA\n",
    "    - for efficiency purposes \n",
    "    - transforming the data to filter relevant information and to reduce redundancy\n",
    "    - Computation of Covariance matrix \n",
    "    - Computation of eigenvectors and eigenvalues \n",
    "    -> Graphically: Diagonalization translates to a rotation of correlation matrix, base vectors being PCs\n",
    "    - Discarding redundant PCs \n",
    "    - coded with numpy (from scratch), short explanation of most important implementation steps\n",
    "- KNN\n",
    "    - In short: How coded? \n",
    "    - euclidean distance...\n",
    "- finding optimal K\n",
    "    - 'proof by exhaustion'\n",
    "- KD-Trees\n",
    "    - Division of space along axis along mean data point, repeat for all axes\n",
    "    - leaf-size: How many data points can be in a dedicated space\n",
    "    - Pathfinding along tree to locate data point, go up on tree to locate any data points 'hiding' in neighboring spaces\n",
    "    - Working uo the tree until the distance between the division axes exceeds distance of data point w/ smallest distance\n",
    "- CNN\n",
    "    - vgg architecture short explanation of architecture \n",
    "    - Convolutions -> Convolution layers\n",
    "    - pooling layers -> max pooling \n",
    "    - Activation function: softmax, relu? \n",
    "    - optimization (adam?)\n",
    "\n",
    "## Evaluationmethods\n",
    "- accuracy -> Formula?\n",
    "    - Computation of accuracy for all PCs and ks, for CNN\n",
    "- confusion matrix\n",
    "    - Chi-square test confusion matrix\n",
    "- recall f1score etc. (ROC Curve evtl.?)\n",
    "\n",
    "# Results\n",
    "- Z-transformation\n",
    "--> img vor & nach Z-transformation (glaube ich nicht nötig)\n",
    "- PCA\n",
    "## pca and optimal ks\n",
    "--> scatterplot 2 PCs (machen wir das noch?)\n",
    "- KNN -> evaluation methods\n",
    "    - proof by exhaustion \n",
    "    - insert plot for all PCs and ks\n",
    "    - var 95% und k=4\n",
    "    - insert code snippet for optimal k and pcs?\n",
    "\n",
    "## knn vs cnn: confusion\n",
    "- confusion matrix for KNN\n",
    "    - confusion shirts, tshirt, coat, pullover\n",
    "CNN: \n",
    "- confusion matrix CNN \n",
    "    - confusion shirts and tshirt\n",
    "\n",
    "- chi-square test matrix\n",
    "\n",
    "## better knn\n",
    "kdtrees: timeit-Funktion, beste leafsize\n",
    "\n",
    "- roc-curve? (nope)\n",
    "\n",
    "## shirts and tshirts problem\n",
    "- confusion between shirts and tshirts\n",
    "- summarized shirts and tshirts: accuracy vs accuracy non summarized\n",
    "- cnn: training just shirts and tshirts and combining with summarized cnn\n",
    "- testing a human: \n",
    "    - print a subdataset of 100 randomized shirts and tshirts\n",
    "    - manual classification yielded 81%\n",
    "\n",
    "# Discussion\n",
    "- what did we expect? \n",
    "    - issue: shirts and tshirts\n",
    "    - cnn better than knn\n",
    "- Why are certain PCs better than others\n",
    "    - 100% of PCs are redundant -> overfitting?\n",
    "    - certain ks are better -> the more k the more problems with 'point clouds' of similar-looking classes that intersect \n",
    "- what was good?\n",
    "    - knn yielded better results than expected but still pales in comparison with cnn \n",
    "- problems & how we overcame them\n",
    "--> Shirts & T-Shirts are hardly differentiable \n",
    "--> Summarizing shirts and tshirts as well as training computer to differentiate just shirts from tshirts\n",
    "- human manual classification yielded 81% -> more humans need to classify for correct prediction but in specific case it shows that ai classified better than a human \n",
    "- comparison KNN & CNN -> chi-squared confusion matrix\n",
    "\n",
    "# Literaturverzeichnis\n",
    "- Datensatz zitieren\n",
    "- introduction: paper von bereits implementierter cnn und knn für fashion mnist\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
